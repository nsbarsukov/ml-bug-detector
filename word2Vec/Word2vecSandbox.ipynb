{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интро и полезная литература"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный файл является скорее демонстрацией того, в чем суть Word2Vec и что он умеет делать. Этот файл - песочница, на которой проводились эксперименты.\n",
    "\n",
    "Все важные функции отсюда будут в дальнейшем перенесены в папку helpers и использованы в дальнейшем анализе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Литература"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Word2vec в картинках](https://habr.com/ru/post/446530/). Статья на хабре от 2019 года.\n",
    "- [Презентация](http://www.machinelearning.ru/wiki/images/b/b3/Word2Vec.pdf) (2017 год) с примерами реализации кода на библиотеке gensim\n",
    " \n",
    "Так как Word2Vec - это уже не просто единичная реализация, а группа алгоритмов для получения векторных представлений слов, то существует масса различных пакетов на эту тему. Мы будем пользоваться gensim.\n",
    "\n",
    "- [Gensim – Руководство для начинающих](https://webdevblog.ru/gensim-rukovodstvo-dlya-nachinajushhih/). Здесь нужно изучить ряд терминов, чтобы понимать принцип работы библиотеки. Статья 2019 года.\n",
    "- [A Beginner’s Guide to Word Embedding with Gensim Word2Vec Model](https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92). Статья 2019 года. По ней хорошо учиться писать код."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Термины"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Токен** обычно означает «слово»\n",
    "- **Документ** обычно может относиться как к «предложению» так и к «абзацу»\n",
    "- **Корпус** обычно представляет собой «собрание документов» в виде пакета слов или как его еще называют мешка слов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт локальных констант и функций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале перейдём на уровень рутового пути репозитория\n",
    "(в дальнейшем всегда пишем пути от корня репозитория)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/n.barsukov/PycharmProjects/ml-bug-detector\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заимпортируем всё, что нам пригодится в дальнейшем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.models import TOKEN_TYPES\n",
    "from shared.helpers.word2VecPreprocessing import filter_tokens_fo_Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также внешние библиотеки подключим сразу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToTokenizeScriptsJson = 'data/parsed-scripts.json'\n",
    "  \n",
    "tokenizedSciptsJson = open(pathToTokenizeScriptsJson) \n",
    "tokenized_scripts = json.load(tokenizedSciptsJson) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = tokenized_scripts['file1082.js']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.read_csv('News_Final.csv')['Headline'][:10000]\n",
    "list_of_lists = [[str(word) for word in str(sentence).split()] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь бы нужно настроить гиперпараметры.\n",
    "\n",
    "[Эта статья](https://habr.com/ru/post/446530/) говорит, что embedding_size устанавливают обычно на 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    # list of lists. Например: [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
    "    sentences=list_of_lists,\n",
    "    \n",
    "    # The number of dimensions of the embeddings and the default is 100\n",
    "    size=300, \n",
    "    \n",
    "    #The maximum distance between a target word and words around the target word. The default window is 5.\n",
    "    window=5,\n",
    "    \n",
    "    # финальный размер словаря\n",
    "    max_final_vocab=10000, \n",
    "    \n",
    "    # игнорировать слова с частотностью ниже, чем эта (регулируется автоматически, если установлено max_final_vocab)\n",
    "    min_count = 0, \n",
    "    \n",
    "    workers=cpu_count(),\n",
    "    \n",
    "    # The training algorithm, either CBOW(0) or skip gram(1). The default training algorithm is CBOW\n",
    "    sg=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('Obama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
