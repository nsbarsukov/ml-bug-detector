# Детектор багов в js-коде (ml-bug-detector)

Данный проект является частью курсовой работы 1 курса магистратуры "Анализ больших данных в бизнесе, экономике и обществе"

## Структура репозитория
- **scripts** - папка с js скриптами (это сырые данные, которые анализируем)
- **scripts-parser** - содержит код, который преобразует js скрипты из папки **scripts** в машиночитаемый формат для дальнейшего анализа
    - **ast** - Abstract Syntax Tree
    - **tokenizer** - создаёт данные-токены, чтобы после скормить их Word2Vec моделе
- **word2Vec** - содержит код для построения модели Word2Vec на python
- **shared** - вынесенные константы и ряд функций python
- **function-based-bug-detector** - применение модели Word2Vec для поиска неправильно использованных аргументов в функциях

## Подготовка окружения
В проекте используется Python и Typescript на Node.js:
- Typescript:
    - Разбиение скриптов, написанных на Javascript, на токены
    (нужны для построение [Word2Vec модели](https://habr.com/ru/post/446530/))
    - Извлечение из скриптов, написанных на Javascript,
    Abstract Syntax Tree
    (нужно для применения Word2Vec модели и поиск багов)
- Python:
    - Построение модели машинного обучения

**Шаги установки по typescript + nodeJS**:
- Скачать и установить [Node.js](https://nodejs.org/en/download/)
- Устновить typescript командой в консоле:
    ~~~~
    npm install -g typescript
    ~~~~
- Открыть терминал исполнить npm-команду
(для этой и всех последующих npm команд данного README использовать терминал от корня репозитория):
    ~~~~
    npm install
    ~~~~

**Шаги установки по Python**:
- установить [Python 3](https://www.python.org/downloads/)
- Открыть терминал и исполнить:
~~~~
pip3 install pandas json gensim multiprocessing tqdm
~~~~

## Парсинг js-файлов
Нужно положить все интересуемые js-файлы в папку scripts ЛЮБОЙ вложенности
(он сам найдёт js-файлы, которые лежат в папке, которая в папке, что завернута в папку ...)

В качестве примера туда сложены уже файлы некоторых репозиториев, написанных на js.

Парсер настроен таким образом, что он игнорирует директории начинающиеся с точки или с названием node_modules.

В данной работе файлы брались с 
[150k Javascript Dataset](https://www.sri.inf.ethz.ch/js150).
В точности, c этого датасета были взяты репозитории, чьи названия начинались b-e
(и кроме репозитория cdnjs)
(на этих данных строилось все изложение курсовой работы).

Вне зависимости от выбранного типа парсинга - результаты будут сложены `./data` в формате json
### Токенизация
~~~~
npm run tokenize
~~~~
Так как это весьма ресурсозатратная операция, то скорее всего дефолтных 1.5 гига у ноды не хватит.
Для таких целей есть следующая команда (делает тоже самое, но использует больше ресурсов системы):
~~~~
npm run high-memory-tokenize
~~~~

_Результат_: разбивает код на слова (при этом проставляет каждому слову тип).
Это будет много json, с именами `tokenized-scripts_{какая-та цифра}.json`

### Извлечение объявлений функций и их вызовы, используя AST
Через Abstract Syntax Tree из скриптов js получилось извлечь места:
- где функции объявлялись (название самой этой функции и названия аргументов этой функции)
- где функции использовались / вызывались (также названия функций и названия аргументов)

Чтобы нода взяла необработанные никак скрипты из папки `./scripts` и извлекла нужную информацию,
необходимо исполнить npm-команду:
~~~~
npm run ast-function-arguments
~~~~

_Результат_: `./data/ast-functions.json`

## Word2Vec модель
Для построения данной модели нужно открыть файл `./word2Vec/buildWord2vecModel.ipynb`.

Результат выполнения данного скрипта (построенная модель) - `word2Vec/word2VecModel`
